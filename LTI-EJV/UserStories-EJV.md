# User Stories - LTI (Leading Talent Intelligence)

**Proyecto:** Sistema ATS con Inteligencia Artificial
**Product Owner:** Equipo LTI
**Versi√≥n:** 1.0
**Fecha:** 2025-01-09

---

# Product Backlog - LTI ATS

## Metodolog√≠a de Priorizaci√≥n

Este backlog ha sido priorizado utilizando **tres metodolog√≠as complementarias** para garantizar una decisi√≥n robusta y balanceada:

1. **MoSCoW**: Clasifica las funcionalidades seg√∫n su criticidad para el MVP y el negocio
2. **Value vs Effort Matrix**: Identifica Quick Wins y Big Bets bas√°ndose en ROI esperado
3. **WSJF (Weighted Shortest Job First)**: Calcula un score cuantitativo considerando valor de negocio, urgencia temporal y reducci√≥n de riesgo

**Proceso de An√°lisis:**
- Cada User Story fue evaluada por valor de negocio (impacto en usuarios, ROI, diferenciaci√≥n competitiva)
- El esfuerzo t√©cnico se estim√≥ considerando complejidad, dependencias t√©cnicas y riesgos de implementaci√≥n
- Las dependencias entre User Stories fueron mapeadas para asegurar un flujo de desarrollo l√≥gico
- Se consider√≥ la viabilidad t√©cnica y disponibilidad de recursos (APIs externas, infraestructura, datos)

**Criterios de Valor:**
- **Impacto en usuarios**: ¬øCu√°ntos usuarios se benefician y con qu√© frecuencia?
- **Diferenciaci√≥n competitiva**: ¬øEs un feature √∫nico que nos distingue de ATS tradicionales?
- **ROI esperado**: ¬øGenera valor inmediato medible (time saved, quality improvement)?
- **Habilitador de otras features**: ¬øDesbloquea desarrollo de otras funcionalidades?

---

## An√°lisis de Priorizaci√≥n

### Enfoque 1: MoSCoW

| User Story | ID | Clasificaci√≥n | Justificaci√≥n |
|------------|-----|---------------|---------------|
| Parseo Inteligente de CV | US-001 | **MUST HAVE** | Foundational - Sin datos estructurados de candidatos no hay sistema. Habilita US-002, US-005, US-006 |
| Screening Automatizado | US-005 | **MUST HAVE** | Core value proposition - El scoring predictivo es el diferenciador principal del producto vs ATS tradicionales |
| Pipeline Visual Kanban | US-011 | **MUST HAVE** | Core UX - Visibilidad del pipeline es la interacci√≥n principal del Recruiter. Sin esto el sistema no es usable |
| Publicaci√≥n Multi-Canal | US-003 | **MUST HAVE** | Acquisition cr√≠tica - Sin candidatos aplicando no hay pipeline que gestionar. Genera tr√°fico inicial |
| Evaluaci√≥n con Scorecards | US-008 | **MUST HAVE** | Evaluaci√≥n estructurada - Fundamental para decisiones de contrataci√≥n basadas en datos (parte del core workflow) |
| B√∫squeda Sem√°ntica | US-002 | **SHOULD HAVE** | Importante para reutilizaci√≥n de talento, pero el MVP puede funcionar con b√∫squeda b√°sica inicialmente |
| Scheduling Autom√°tico | US-007 | **SHOULD HAVE** | Gran time-saver (80%) pero las entrevistas pueden coordinarse manualmente en MVP si es necesario |
| Feedback Consolidado | US-010 | **SHOULD HAVE** | Mejora significativa en quality de decisiones, pero los scorecards individuales pueden revisarse manualmente |
| Aprobaci√≥n de Jobs | US-004 | **SHOULD HAVE** | Governance importante, pero no bloqueante - puede manejarse externamente en MVP |
| Auto-Tagging | US-006 | **COULD HAVE** | Efficiency feature - Muy √∫til pero los recruiters pueden filtrar/buscar de otras formas |
| Colaboraci√≥n Real-Time | US-009 | **COULD HAVE** | Nice to have - La colaboraci√≥n puede hacerse v√≠a email/Slack inicialmente |
| Dashboard Analytics | US-012 | **COULD HAVE** | Insights valiosos pero no cr√≠ticos para MVP - puede agregarse cuando haya datos hist√≥ricos suficientes |

**Resultado MoSCoW:**
- **Must Have (5)**: US-001, US-005, US-011, US-003, US-008
- **Should Have (4)**: US-002, US-007, US-010, US-004
- **Could Have (3)**: US-006, US-009, US-012
- **Won't Have (0)**: Ninguna US descartada completamente

---

### Enfoque 2: Value vs Effort Matrix

| Cuadrante | User Story | ID | Valor | Esfuerzo | Razonamiento |
|-----------|------------|-----|-------|----------|--------------|
| **QUICK WINS** | Scorecards Estructurados | US-008 | Alto | Medio (M) | Alto impacto en decisiones, complejidad moderada. ROI inmediato |
| **QUICK WINS** | Feedback Consolidado | US-010 | Medio-Alto | Medio (M) | Mejora quality decisiones, implementaci√≥n directa sobre US-008 |
| **QUICK WINS** | Auto-Tagging | US-006 | Medio | Medio (M) | Efficiency gain claro, rule engine relativamente simple |
| **QUICK WINS** | Aprobaci√≥n de Jobs | US-004 | Medio | Medio (M) | Workflow est√°ndar, sin integraciones complejas |
| **BIG BETS** | Parseo de CV con IA | US-001 | Muy Alto | Alto (L) | Foundational + diferenciador IA. Complejidad NLP significativa |
| **BIG BETS** | Screening Automatizado | US-005 | Muy Alto | Muy Alto (XL) | Core value prop. Requiere ML model, training data, feature engineering |
| **BIG BETS** | Pipeline Kanban | US-011 | Muy Alto | Alto (L) | Core UX esencial. Drag-and-drop + real-time moderadamente complejo |
| **BIG BETS** | Publicaci√≥n Multi-Canal | US-003 | Alto | Muy Alto (XL) | Critical acquisition. M√∫ltiples integraciones API (LinkedIn, Indeed, Glassdoor) |
| **BIG BETS** | B√∫squeda Sem√°ntica | US-002 | Medio-Alto | Alto (L) | Reuse importante. Requiere Elasticsearch + embeddings |
| **FILL-INS** | Scheduling Autom√°tico | US-007 | Alto | Muy Alto (XL) | Gran time-saver pero esfuerzo desproporcionado (calendar + video APIs) |
| **TIME SINKS** | Colaboraci√≥n Real-Time | US-009 | Medio | Alto (L) | Benefit marginal vs email. WebSockets + complejidad no justificada en MVP |
| **TIME SINKS** | Dashboard Analytics | US-012 | Medio | Muy Alto (XL) | Nice insights pero requiere Analytics Service completo + ETL. Mejor post-MVP |

**Matriz Visual:**

```
ALTO VALOR
    ‚îÇ  US-008 ‚îÇ US-001, US-005
    ‚îÇ  US-010 ‚îÇ US-011, US-003
    ‚îÇ  US-006 ‚îÇ US-002
    ‚îÇ  US-004 ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ESFUERZO
    ‚îÇ         ‚îÇ US-007, US-009
    ‚îÇ         ‚îÇ US-012
BAJO VALOR
    BAJO      ALTO
```

**Recomendaci√≥n Value/Effort:**
1. **Priorizar primero**: Quick Wins (US-008, US-010, US-006, US-004)
2. **Luego**: Big Bets cr√≠ticos (US-001, US-005, US-011, US-003)
3. **Evaluar**: US-007 (alto valor pero esfuerzo XL - considerar MVP simplificado)
4. **Postponer**: US-009, US-012 (mejor ROI en fases posteriores)

---

### Enfoque 3: WSJF (Weighted Shortest Job First)

**F√≥rmula WSJF**: (Business Value + Time Criticality + Risk Reduction) / Job Size

**Escala**: 1-10 para cada factor (10 = m√°ximo)

| Rank | User Story | ID | Business Value | Time Criticality | Risk Reduction | Job Size | **WSJF Score** |
|------|------------|-----|----------------|------------------|----------------|----------|----------------|
| 1 | Scorecards Estructurados | US-008 | 8 | 8 | 7 | 5 | **4.60** |
| 2 | Parseo de CV con IA | US-001 | 10 | 10 | 9 | 8 | **3.625** |
| 3 | Feedback Consolidado | US-010 | 7 | 5 | 6 | 5 | **3.60** |
| 4 | Pipeline Kanban | US-011 | 10 | 10 | 8 | 8 | **3.50** |
| 5 | Screening Automatizado | US-005 | 10 | 10 | 10 | 10 | **3.00** |
| 6 | Auto-Tagging | US-006 | 6 | 4 | 3 | 5 | **2.60** |
| 7 | Publicaci√≥n Multi-Canal | US-003 | 9 | 8 | 7 | 10 | **2.40** |
| 8 | Aprobaci√≥n de Jobs | US-004 | 5 | 3 | 4 | 5 | **2.40** |
| 9 | B√∫squeda Sem√°ntica | US-002 | 7 | 5 | 6 | 8 | **2.25** |
| 10 | Scheduling Autom√°tico | US-007 | 8 | 7 | 6 | 10 | **2.10** |
| 11 | Colaboraci√≥n Real-Time | US-009 | 6 | 4 | 5 | 8 | **1.875** |
| 12 | Dashboard Analytics | US-012 | 6 | 3 | 4 | 10 | **1.30** |

**Desglose de Scores:**

**US-008 (Scorecards)**: WSJF = 4.60
- BV=8: Decisiones de calidad, evaluaci√≥n estructurada (core workflow)
- TC=8: Necesario temprano para capturar feedback de entrevistas
- RR=7: Reduce riesgo de malas contrataciones, asegura consistencia
- JS=5: Medio - Templates + forms + validaci√≥n

**US-001 (Parseo CV)**: WSJF = 3.625
- BV=10: Foundational - habilita todo el sistema
- TC=10: Sin esto no hay candidatos estructurados
- RR=9: Elimina riesgo de datos inconsistentes, calidad de data cr√≠tica
- JS=8: Alto - NLP, multiple formats, normalizaci√≥n

**US-010 (Feedback Consolidado)**: WSJF = 3.60
- BV=7: Mejora decisiones significativamente
- TC=5: Importante pero puede posponerse ligeramente
- RR=6: Reduce riesgo de decisiones basadas en data incompleta
- JS=5: Medio - Aggregation queries + charts + PDF export

**US-011 (Pipeline Kanban)**: WSJF = 3.50
- BV=10: Core UX, interacci√≥n principal
- TC=10: Sin visualizaci√≥n del pipeline el sistema no es usable
- RR=8: Reduce riesgo de candidatos perdidos, bottlenecks no identificados
- JS=8: Alto - Drag-and-drop + real-time + filtros

**US-005 (Screening)**: WSJF = 3.00
- BV=10: Core value prop, diferenciador #1
- TC=10: Define la propuesta de valor √∫nica
- RR=10: Reduce riesgo competitivo m√°ximo, prueba de concepto AI
- JS=10: Muy alto - ML model, training pipeline, feature engineering, MLflow

**Interpretaci√≥n WSJF:**
- **Top 4 (WSJF > 3.5)**: US-008, US-001, US-010, US-011 ‚Üí M√°xima prioridad
- **Mid-tier (WSJF 2.4-3.0)**: US-005, US-006, US-003, US-004 ‚Üí Segunda ola
- **Lower priority (WSJF < 2.3)**: US-002, US-007, US-009, US-012 ‚Üí Backlog futuro

---

## Backlog Priorizado Final

**Metodolog√≠a de S√≠ntesis:**
Combinamos los 3 enfoques ponderando:
- **MoSCoW**: 40% (define criticidad de negocio)
- **Value/Effort**: 35% (optimiza ROI)
- **WSJF**: 25% (balancea valor y tama√±o)

Adem√°s consideramos:
- **Dependencias t√©cnicas**: US que habilitan otras tienen boost de prioridad
- **Riesgo de integraci√≥n**: Features con APIs externas complejas se escalonan
- **Capacidad del equipo**: Balancear XL stories con M/L para mantener velocity

| **Prioridad** | **US** | **T√≠tulo** | **Sprint** | **Esfuerzo** | **MoSCoW** | **V/E** | **WSJF** | **Justificaci√≥n** |
|---------------|--------|------------|------------|--------------|------------|---------|----------|-------------------|
| **P1** | US-001 | Parseo de CV con IA | Sprint 1 | L (2-3w) | Must | Big Bet | 3.62 | **FOUNDATIONAL** - Habilita US-002, US-005, US-006. Sin datos estructurados no hay sistema. Alta prioridad en los 3 enfoques |
| **P2** | US-011 | Pipeline Kanban | Sprint 1 | L (2-3w) | Must | Big Bet | 3.50 | **CORE UX** - Interacci√≥n principal del Recruiter. Must Have + WSJF alto. Desarrollar en paralelo con US-001 |
| **P3** | US-008 | Scorecards | Sprint 2 | M (1-2w) | Must | Quick Win | 4.60 | **QUICK WIN** - WSJF m√°s alto (4.6). Evaluaci√≥n estructurada cr√≠tica. Esfuerzo moderado, alto impacto |
| **P4** | US-005 | Screening Automatizado | Sprint 2 | XL (3-4w) | Must | Big Bet | 3.00 | **CORE VALUE PROP** - Diferenciador AI principal. Depende de US-001. Must Have cr√≠tico |
| **P5** | US-003 | Publicaci√≥n Multi-Canal | Sprint 3 | XL (3-4w) | Must | Big Bet | 2.40 | **ACQUISITION** - Sin candidatos aplicando no hay pipeline. Complejidad alta pero cr√≠tico para traction |
| **P6** | US-010 | Feedback Consolidado | Sprint 3 | M (1-2w) | Should | Quick Win | 3.60 | **QUICK WIN** - WSJF alto (3.6). Depende de US-008. Mejora calidad decisiones significativamente |
| **P7** | US-006 | Auto-Tagging | Sprint 4 | M (1-2w) | Could | Quick Win | 2.60 | **EFFICIENCY** - Depende de US-005. Quick Win con effort moderado. Mejora UX post-MVP |
| **P8** | US-004 | Aprobaci√≥n de Jobs | Sprint 4 | M (1-2w) | Should | Fill-In | 2.40 | **GOVERNANCE** - Should Have. Puede implementarse cuando hay flujo real de jobs. Effort bajo |
| **P9** | US-002 | B√∫squeda Sem√°ntica | Sprint 5 | L (2-3w) | Should | Big Bet | 2.25 | **TALENT REUSE** - Depende de US-001. Importante cuando hay base de datos poblada (post-MVP) |
| **P10** | US-007 | Scheduling Autom√°tico | Backlog | XL (3-4w) | Should | Fill-In | 2.10 | **BIG TIME-SAVER** - Alto valor pero esfuerzo XL desproporcionado. Considerar MVP manual o v2 simplificada |
| **P11** | US-009 | Colaboraci√≥n Real-Time | Backlog | L (2-3w) | Could | Time Sink | 1.87 | **NICE TO HAVE** - Colaboraci√≥n puede ser v√≠a email/Slack inicialmente. WebSockets es overhead para MVP |
| **P12** | US-012 | Dashboard Analytics | Backlog | XL (3-4w) | Could | Time Sink | 1.30 | **INSIGHTS** - Valioso cuando hay datos hist√≥ricos (6+ meses). Requiere Analytics Service completo. Fase 2 |

---

## Roadmap de Sprints Sugerido

**Asunciones:**
- **Duraci√≥n de Sprint**: 2 semanas
- **Velocidad del Equipo**: ~3-4 semanas de esfuerzo por sprint (team de 3-4 devs)
- **Paralelizaci√≥n**: US independientes pueden desarrollarse en paralelo

---

### **Sprint 1: MVP Foundation (Semanas 1-2)**
**Objetivo**: Establecer la fundaci√≥n t√©cnica y la UX core del sistema

**User Stories:**
- ‚úÖ **US-001: Parseo de CV** (L - 2-3 semanas) - *Track 1: Backend + AI*
- ‚úÖ **US-011: Pipeline Kanban** (L - 2-3 semanas) - *Track 2: Frontend*

**Entregables:**
- Sistema de parsing de CVs funcional (PDF, Word, LinkedIn)
- Base de datos de candidatos estructurada poblable
- Tablero Kanban visual con drag-and-drop
- Gesti√≥n b√°sica de etapas de candidatos

**Riesgos:**
- Precisi√≥n del parser puede requerir iteraciones
- Integraci√≥n LinkedIn API puede tener delays (requiere partnership)

**Mitigaci√≥n:**
- Comenzar con parser b√°sico (PDF/Word) y agregar LinkedIn incrementalmente
- Tener fallback a entrada manual si parsing falla

---

### **Sprint 2: Core Intelligence (Semanas 3-4)**
**Objetivo**: Implementar el diferenciador IA y evaluaci√≥n estructurada

**User Stories:**
- ‚úÖ **US-008: Scorecards** (M - 1-2 semanas) - *Quick Win*
- ‚úÖ **US-005: Screening Automatizado** (XL - 3-4 semanas, **inicia aqu√≠, termina Sprint 3**) - *Big Bet*

**Entregables:**
- Templates de scorecards por tipo de entrevista
- Formularios de evaluaci√≥n estructurada
- Modelo ML de scoring entrenado (v1)
- Auto-scoring de candidatos funcionando

**Dependencias Cr√≠ticas:**
- **US-005 requiere**: Dataset hist√≥rico etiquetado (m√≠nimo 5k aplicaciones)
- **US-008 requiere**: Modelo de datos INTERVIEW completado

**Nota**: US-005 es XL (3-4 semanas), comenzar√° en Sprint 2 pero continuar√° en Sprint 3

---

### **Sprint 3: Acquisition & Decision Quality (Semanas 5-6)**
**Objetivo**: Habilitar acquisition de candidatos y mejorar quality de decisiones

**User Stories:**
- ‚úÖ **US-005: Screening Automatizado** (contin√∫a desde Sprint 2)
- ‚úÖ **US-003: Publicaci√≥n Multi-Canal** (XL - 3-4 semanas, **inicia aqu√≠, termina Sprint 4**)
- ‚úÖ **US-010: Feedback Consolidado** (M - 1-2 semanas) - *Quick Win*

**Entregables:**
- Match Score predictivo operacional
- Integraciones con LinkedIn, Indeed, Glassdoor (al menos 2)
- One-click job publishing funcional
- Vista consolidada de feedback de entrevistas
- Export a PDF de evaluaciones

**Riesgos:**
- APIs externas pueden tener sandboxes limitados
- Rate limits en job boards

**Mitigaci√≥n:**
- Desarrollar adaptadores mock para testing
- Implementar queue-based publishing con retry logic

---

### **Sprint 4: Polish & Governance (Semanas 7-8)**
**Objetivo**: Refinamiento de UX y procesos de governance

**User Stories:**
- ‚úÖ **US-003: Publicaci√≥n Multi-Canal** (contin√∫a desde Sprint 3)
- ‚úÖ **US-006: Auto-Tagging** (M - 1-2 semanas)
- ‚úÖ **US-004: Aprobaci√≥n de Jobs** (M - 1-2 semanas)

**Entregables:**
- Multi-channel publishing completo con tracking UTM
- Sistema de tagging autom√°tico con 9+ reglas
- Workflow de aprobaci√≥n HM ‚Üí Recruiter
- MVP completo y funcional

**Milestone**: üéâ **MVP READY** - Sistema listo para beta testing con primeros clientes

---

### **Sprint 5-6: Enhancement & Scale (Semanas 9-12) - Post-MVP**
**Objetivo**: Features de valor agregado y preparaci√≥n para escala

**User Stories:**
- ‚úÖ **US-002: B√∫squeda Sem√°ntica** (L - 2-3 semanas)
- ‚úÖ **US-007: Scheduling Autom√°tico** (XL - 3-4 semanas, **MVP simplificado**)

**Entregables:**
- Motor de b√∫squeda sem√°ntica con Elasticsearch
- Embeddings de skills implementados
- Scheduling autom√°tico con calendarios (versi√≥n simplificada: solo Google Calendar inicialmente)

**Consideraciones:**
- **US-007**: Implementar MVP con solo Google Calendar + Zoom (reduce esfuerzo de XL a L)
- Agregar Outlook + Teams en iteraci√≥n futura
- Elasticsearch requiere infraestructura adicional - provisionar en Sprint 4

---

### **Backlog Futuro (Post-Sprint 6)**

**Features para Fase 2:**
- **US-009: Colaboraci√≥n Real-Time** - Cuando hay m√∫ltiples usuarios activos simult√°neamente
- **US-012: Dashboard Analytics** - Cuando hay 3-6 meses de datos hist√≥ricos para m√©tricas significativas

**Evoluciones Potenciales:**
- **US-007 completo**: Agregar Outlook + Teams, scheduling para panels de 5+ personas
- **US-002 avanzado**: Agregar ML recommendations "Candidatos similares a este"
- **US-005 v2**: Reentrenamiento autom√°tico del modelo cada semana
- **Integraciones adicionales**: HackerRank, Codility, background checks

---

## Tabla Comparativa de Metodolog√≠as

An√°lisis de c√≥mo cada metodolog√≠a impact√≥ la priorizaci√≥n final:

| User Story | MoSCoW Rank | V/E Rank | WSJF Rank | **Final Rank** | Concordancia | Observaciones |
|------------|-------------|----------|-----------|----------------|--------------|---------------|
| US-008 (Scorecards) | 5 (Must) | 1 (QW) | **1** | **P3** | ‚ö†Ô∏è Divergente | WSJF lo coloca #1 pero dependencias t√©cnicas lo mueven a Sprint 2 |
| US-001 (Parseo CV) | 1 (Must) | 5 (BB) | **2** | **P1** | ‚úÖ Alta | Consenso en top 3 de todas las metodolog√≠as. Foundational |
| US-011 (Kanban) | 3 (Must) | 7 (BB) | **4** | **P2** | ‚úÖ Alta | Must Have + Core UX. Concordancia en top 5 |
| US-005 (Screening) | 2 (Must) | 6 (BB) | **5** | **P4** | ‚úÖ Alta | Core value prop. WSJF penalizado por job size (XL) |
| US-003 (Multi-Canal) | 4 (Must) | 8 (BB) | 7 | **P5** | ‚ö†Ô∏è Media | Must Have pero esfuerzo XL retrasa ejecuci√≥n |
| US-010 (Feedback) | 8 (Should) | 2 (QW) | **3** | **P6** | ‚ö†Ô∏è Divergente | WSJF alto pero Should Have en MoSCoW. Depende de US-008 |
| US-006 (Tagging) | 10 (Could) | 3 (QW) | 6 | **P7** | ‚ö†Ô∏è Media | Could Have pero Quick Win con buen WSJF. Post-MVP |
| US-004 (Aprobaci√≥n) | 9 (Should) | 4 (FI) | 8 | **P8** | ‚úÖ Alta | Concordancia en tier medio. Governance importante pero no urgente |
| US-002 (B√∫squeda) | 6 (Should) | 9 (BB) | 9 | **P9** | ‚úÖ Alta | Should Have. Depende de US-001. Post-MVP |
| US-007 (Scheduling) | 7 (Should) | 10 (FI) | 10 | **P10** | ‚úÖ Alta | Alto valor pero effort XL desproporcionado. Considerar MVP simplificado |
| US-009 (Collab RT) | 11 (Could) | 11 (TS) | 11 | **P11** | ‚úÖ Alta | Consenso en baja prioridad. Nice to have para Fase 2 |
| US-012 (Analytics) | 12 (Could) | 12 (TS) | 12 | **P12** | ‚úÖ Alta | Consenso un√°nime en backlog futuro. Requiere datos hist√≥ricos |

**Leyenda:**
- QW: Quick Win | BB: Big Bet | FI: Fill-In | TS: Time Sink
- ‚úÖ Alta concordancia (ranking similar en 2+ metodolog√≠as)
- ‚ö†Ô∏è Divergencia (rankings var√≠an >3 posiciones entre metodolog√≠as)

---

## Insights del An√°lisis Multi-Metodol√≥gico

### 1. **Consenso Fuerte (Top Priorities)**
Las siguientes US tienen **alta concordancia** en las 3 metodolog√≠as:
- **US-001 (Parseo CV)**: Foundational indiscutible
- **US-005 (Screening)**: Core value prop reconocido
- **US-011 (Kanban)**: Core UX esencial
- **US-003 (Multi-Canal)**: Acquisition cr√≠tica

**Recomendaci√≥n**: Estos 4 forman el **n√∫cleo del MVP** (Sprints 1-3)

### 2. **Quick Wins Identificados**
Value/Effort matrix revela **oportunidades de ROI r√°pido**:
- **US-008 (Scorecards)**: M effort, alto impacto ‚Üí Sprint 2
- **US-010 (Feedback)**: M effort, mejora decisiones ‚Üí Sprint 3
- **US-006 (Tagging)**: M effort, efficiency gain ‚Üí Sprint 4

**Recomendaci√≥n**: Intercalar Quick Wins entre Big Bets para mantener momentum

### 3. **Divergencias Notables**

**US-008 (Scorecards)**:
- WSJF: Rank #1 (score 4.60)
- MoSCoW: Must Have (#5)
- V/E: Quick Win (#1)
- **Decisi√≥n**: Prioridad P3 (Sprint 2) - Balance entre WSJF alto y dependencias t√©cnicas

**US-010 (Feedback Consolidado)**:
- WSJF: Rank #3 (score 3.60)
- MoSCoW: Should Have (#8)
- V/E: Quick Win (#2)
- **Decisi√≥n**: Prioridad P6 (Sprint 3) - Depende de US-008, pero quick win claro

**An√°lisis**: WSJF favorece features con menor job size (M vs XL), revelando oportunidades que MoSCoW puede subestimar

### 4. **Big Bets con ROI a Largo Plazo**

Features con **esfuerzo XL pero Must Have**:
- **US-005 (Screening)**: 3-4 semanas pero core differentiator
- **US-003 (Multi-Canal)**: 3-4 semanas pero habilita acquisition
- **US-007 (Scheduling)**: 3-4 semanas pero 80% time reduction

**Estrategia**:
- US-005 y US-003: Invertir el esfuerzo XL (son Must Have)
- US-007: Considerar **MVP simplificado** (solo Google Calendar) para reducir a L

### 5. **Features para Backlog Futuro**

**Consenso en postponer**:
- **US-009 (Colaboraci√≥n RT)**: WebSockets es overhead innecesario en MVP
- **US-012 (Analytics)**: Sin datos hist√≥ricos (6+ meses) las m√©tricas no son significativas

**Trigger para reactivar**:
- US-009: Cuando >20 usuarios concurrentes activos
- US-012: Despu√©s de 3-6 meses de operaci√≥n con datos reales

### 6. **Impacto de Dependencias T√©cnicas**

**Cadenas de dependencia cr√≠ticas**:
1. **US-001 ‚Üí US-005 ‚Üí US-006**: Parseo habilita screening habilita tagging
2. **US-008 ‚Üí US-010**: Scorecards habilitan consolidaci√≥n de feedback
3. **US-001 ‚Üí US-002**: Parseo habilita b√∫squeda sem√°ntica

**Implicaci√≥n**: El ordenamiento final respeta estas cadenas incluso cuando WSJF sugiere otro orden

---

## Recomendaciones Finales

### Para Product Owner:
1. **Validar priorizaci√≥n** con stakeholders clave (Recruiters, Hiring Managers)
2. **Confirmar disponibilidad** de dataset hist√≥rico para US-005 (m√≠nimo 5k aplicaciones etiquetadas)
3. **Negociar partnerships** con LinkedIn, Indeed, Glassdoor para APIs de US-003
4. **Definir m√©tricas de √©xito** por sprint (KPIs de adopci√≥n, quality, performance)

### Para Engineering Lead:
1. **Provisionar infraestructura** temprano: AWS S3 (CVs), Elasticsearch (b√∫squeda), MLflow (modelos)
2. **Recrutar/training** en ML para US-005: modelo XGBoost, feature engineering, MLOps
3. **Establecer arquitectura** de microservicios desde Sprint 1 para escalabilidad
4. **Configurar CI/CD** y ambientes (dev/staging/prod) antes de Sprint 1

### Para Sprint Planning:
1. **Sprint 1-2**: Enfoque en fundaci√≥n (US-001, US-011) + quick win (US-008)
2. **Sprint 3-4**: Core differentiation (US-005) + acquisition (US-003)
3. **Sprint 5-6**: Enhancement features (US-002, US-007 simplificado)
4. **Backlog futuro**: Re-evaluar US-009, US-012 despu√©s de 6 meses de operaci√≥n

### M√©tricas de √âxito del MVP (Post-Sprint 4):
- ‚úÖ **Parsing accuracy**: >85% en campos cr√≠ticos
- ‚úÖ **Match Score AUC-ROC**: >0.75
- ‚úÖ **Jobs publicados**: 50+ en primeros 30 d√≠as
- ‚úÖ **Time-to-hire**: Reducci√≥n medible vs baseline manual
- ‚úÖ **User adoption**: 15+ beta customers activos
- ‚úÖ **NPS**: >40 en primeros usuarios

---

**Pr√≥xima Revisi√≥n**: Re-evaluar backlog despu√©s de Sprint 4 (MVP complete) bas√°ndose en feedback de beta users y m√©tricas reales de adopci√≥n.

---

## √çndice de User Stories

### A. Gesti√≥n de Candidatos
- [US-001: Parseo Inteligente de CV con IA](#us-001-parseo-inteligente-de-cv-con-ia)
- [US-002: B√∫squeda Sem√°ntica en Base de Talentos](#us-002-b√∫squeda-sem√°ntica-en-base-de-talentos)

### B. Gesti√≥n de Vacantes
- [US-003: Publicaci√≥n Multi-Canal de Ofertas de Trabajo](#us-003-publicaci√≥n-multi-canal-de-ofertas-de-trabajo)
- [US-004: Flujo de Aprobaci√≥n de Ofertas de Trabajo](#us-004-flujo-de-aprobaci√≥n-de-ofertas-de-trabajo)

### C. Screening y Matching con IA
- [US-005: Screening Automatizado con Scoring Predictivo](#us-005-screening-automatizado-con-scoring-predictivo)
- [US-006: Etiquetado Inteligente Autom√°tico de Candidatos](#us-006-etiquetado-inteligente-autom√°tico-de-candidatos)

### D. Gesti√≥n de Entrevistas
- [US-007: Programaci√≥n Autom√°tica de Entrevistas con Integraci√≥n de Calendarios](#us-007-programaci√≥n-autom√°tica-de-entrevistas-con-integraci√≥n-de-calendarios)
- [US-008: Evaluaci√≥n Estructurada con Scorecards](#us-008-evaluaci√≥n-estructurada-con-scorecards)

### E. Colaboraci√≥n y Toma de Decisiones
- [US-009: Evaluaci√≥n Colaborativa en Tiempo Real](#us-009-evaluaci√≥n-colaborativa-en-tiempo-real)
- [US-010: Vista Consolidada de Feedback de Entrevistas](#us-010-vista-consolidada-de-feedback-de-entrevistas)

### F. Gesti√≥n del Pipeline
- [US-011: Pipeline Visual Kanban para Gesti√≥n de Candidatos](#us-011-pipeline-visual-kanban-para-gesti√≥n-de-candidatos)

### G. Anal√≠tica y Reporting
- [US-012: Dashboard de M√©tricas de Reclutamiento en Tiempo Real](#us-012-dashboard-de-m√©tricas-de-reclutamiento-en-tiempo-real)

---

## Leyenda de Prioridades

| Prioridad | Descripci√≥n | Criterio |
|-----------|-------------|----------|
| **Alta** | Funcionalidad cr√≠tica para MVP o valor de negocio inmediato | Debe estar en las primeras 2-3 iteraciones |
| **Media** | Funcionalidad importante pero no bloqueante | Puede desarrollarse en iteraciones 4-6 |
| **Baja** | Funcionalidad deseable, mejora la experiencia | Se puede posponer para fases posteriores |

## Leyenda de Estimaciones (T-Shirt Sizing)

| Tama√±o | Descripci√≥n | Complejidad | Duraci√≥n Estimada |
|--------|-------------|-------------|-------------------|
| **XS** | Tarea muy simple, cambio menor | M√≠nima | 1-2 d√≠as |
| **S** | Tarea simple con dependencias limitadas | Baja | 3-5 d√≠as |
| **M** | Tarea moderada, requiere dise√±o y testing | Media | 1-2 semanas |
| **L** | Tarea compleja, m√∫ltiples componentes | Alta | 2-3 semanas |
| **XL** | √âpica o tarea muy compleja, considerar divisi√≥n | Muy alta | 3-4 semanas o m√°s |

## Convenciones Utilizadas

- **Roles de Usuario:** Recruiter (Reclutador), Hiring Manager (Gerente de Contrataci√≥n), Interviewer (Entrevistador), Admin (Administrador)
- **DoD:** Definition of Done (Definici√≥n de Hecho)
- **API:** Application Programming Interface
- **NLP:** Natural Language Processing
- **ML:** Machine Learning
- **RBAC:** Role-Based Access Control
- **SLA:** Service Level Agreement

---

# User Stories Detalladas

---

## US-001: Parseo Inteligente de CV con IA

**Como** Recruiter
**Quiero** que el sistema extraiga autom√°ticamente informaci√≥n estructurada de los CVs que suben los candidatos (PDF, Word, LinkedIn)
**Para** ahorrar tiempo de entrada manual de datos y garantizar que todos los perfiles est√©n completos y normalizados desde el primer momento

### Criterios de Aceptaci√≥n

- [ ] El sistema acepta m√∫ltiples formatos de CV: PDF, DOCX, TXT, y URLs de LinkedIn
- [ ] El parser extrae autom√°ticamente con >85% de precisi√≥n: nombre completo, email, tel√©fono, ubicaci√≥n, a√±os de experiencia total, t√≠tulo actual, empresa actual, historial laboral (empresa, puesto, fechas), educaci√≥n (instituci√≥n, t√≠tulo, fechas), habilidades t√©cnicas, y certificaciones
- [ ] Los datos extra√≠dos se almacenan en formato estructurado en la base de datos (tabla CANDIDATE y JSON en campo parsed_resume)
- [ ] El sistema normaliza nombres de habilidades usando un diccionario (ej: "React.js" = "React" = "ReactJS")
- [ ] Si el parsing falla o tiene baja confianza (<60%), el sistema marca el candidato para revisi√≥n manual y notifica al Recruiter
- [ ] El sistema muestra una vista de "datos extra√≠dos" editable donde el Recruiter puede corregir informaci√≥n incorrecta antes de guardar
- [ ] El proceso de parsing se completa en menos de 30 segundos para el 95% de los CVs
- [ ] El sistema detecta y alerta sobre CVs duplicados bas√°ndose en email o combinaci√≥n nombre+tel√©fono

### Notas T√©cnicas

- **Stack tecnol√≥gico:** Python + FastAPI para servicio de IA, spaCy para NER (Named Entity Recognition), biblioteca PyPDF2/pdfplumber para PDFs, python-docx para Word
- **Modelo NLP:** Usar spaCy pre-entrenado en espa√±ol/ingl√©s con fine-tuning en dataset de CVs t√©cnicos (m√≠nimo 5,000 CVs etiquetados)
- **OCR para PDFs complejos:** Integrar AWS Textract o Google Vision API para ~10% de PDFs con formato complejo o escaneados
- **Normalizaci√≥n de habilidades:** Mantener diccionario maestro en tabla SKILLS con sin√≥nimos y variaciones
- **API de LinkedIn:** Utilizar API oficial de LinkedIn (requiere partnership) o scraping autorizado con consentimiento del candidato
- **Cach√©:** Cachear resultados de parsing por hash del documento para evitar reprocesamiento
- **Cola as√≠ncrona:** Usar RabbitMQ o AWS SQS para procesar parsing en background sin bloquear UI
- **Almacenamiento:** CVs originales en AWS S3 con versionado, datos estructurados en PostgreSQL + MongoDB para JSON
- **Fallback a LLM:** Para 5% de CVs con formato no est√°ndar, usar GPT-4 o Claude API como fallback (costo-beneficio a evaluar)

### Definici√≥n de Hecho (DoD)

- [ ] C√≥digo implementado en servicio AI Screening con endpoints REST documentados en Swagger
- [ ] Tests unitarios con cobertura >80% para cada extractor (nombre, email, skills, etc.)
- [ ] Tests de integraci√≥n con ejemplos reales de CVs en diferentes formatos (m√≠nimo 50 casos de prueba)
- [ ] Performance testing: 100 CVs procesados en paralelo sin degradaci√≥n (<30s p95)
- [ ] Documentaci√≥n t√©cnica: arquitectura del parser, modelos utilizados, diccionario de skills, instrucciones de fine-tuning
- [ ] M√©tricas de precisi√≥n medidas en dataset de validaci√≥n (>85% accuracy por campo)
- [ ] Logs estructurados con trazabilidad completa (correlation IDs)
- [ ] Manejo de errores con reintentos exponenciales y circuit breaker
- [ ] Aprobado por Product Owner en demo con CVs reales del equipo

### Prioridad: Alta
### Estimaci√≥n Inicial: L (2-3 semanas)
### Dependencias:
- Infraestructura de microservicios base (AI Screening Service)
- Modelo de datos CANDIDATE y CANDIDATE_SKILL implementado
- Almacenamiento S3 o equivalente configurado

---

## US-002: B√∫squeda Sem√°ntica en Base de Talentos

**Como** Recruiter
**Quiero** buscar candidatos en la base de datos usando lenguaje natural y filtros sem√°nticos (ej: "desarrollador full-stack con React en Madrid con m√°s de 3 a√±os de experiencia")
**Para** encontrar r√°pidamente candidatos relevantes para nuevas posiciones sin depender de palabras clave exactas, reutilizando el talento existente

### Criterios de Aceptaci√≥n

- [ ] El sistema permite b√∫squeda en lenguaje natural procesando la query con NLP para extraer intenci√≥n (skills, ubicaci√≥n, experiencia, etc.)
- [ ] La b√∫squeda entiende sin√≥nimos y variaciones de habilidades (ej: "JavaScript" encuentra tambi√©n "JS", "Node.js", "React")
- [ ] Los resultados se ordenan por relevancia usando un score de similitud sem√°ntica (0-100)
- [ ] El sistema muestra en cada resultado: nombre, foto, t√≠tulo actual, a√±os de experiencia, ubicaci√≥n, top 5 skills, match score, y √∫ltima interacci√≥n
- [ ] Filtros avanzados aplicables: ubicaci√≥n (con radio geogr√°fico), rango de a√±os de experiencia, nivel educativo, disponibilidad, estado de autorizaci√≥n de trabajo, empresas previas, √∫ltima aplicaci√≥n (rango de fechas)
- [ ] La b√∫squeda devuelve resultados en menos de 2 segundos para queries sobre bases de hasta 100,000 candidatos
- [ ] El sistema guarda las b√∫squedas frecuentes y permite crear "Saved Searches" con alertas cuando nuevos candidatos coinciden
- [ ] La interfaz sugiere autocompletado de habilidades y ubicaciones mientras el usuario escribe

### Notas T√©cnicas

- **Motor de b√∫squeda:** Elasticsearch 8 con √≠ndices optimizados para full-text search y semantic search
- **Embeddings sem√°nticos:** Generar vectores de skills usando modelos pre-entrenados (Sentence-BERT, all-MiniLM-L6-v2) y almacenar en Elasticsearch con campo dense_vector
- **Scoring h√≠brido:** Combinar BM25 (keyword matching) + cosine similarity (semantic matching) con pesos configurables (60% sem√°ntico, 40% keyword)
- **NLP para query parsing:** Usar spaCy NER para extraer entidades de la query (skills ‚Üí etiquetas SKILL, ciudades ‚Üí etiquetas GPE, n√∫meros ‚Üí a√±os experiencia)
- **Sin√≥nimos:** Mantener diccionario de sin√≥nimos en Elasticsearch synonym filter (React: [react, reactjs, react.js])
- **√çndices:** Crear √≠ndices compuestos en PostgreSQL para filtros comunes (location + years_experience, skills + availability)
- **Cach√©:** Redis para cachear queries frecuentes (TTL 5 minutos)
- **Geolocalizaci√≥n:** Usar Elasticsearch geo_distance query para b√∫squedas por radio geogr√°fico
- **Paginaci√≥n:** Implementar cursor-based pagination para grandes resultados (evitar OFFSET ineficiente)
- **An√°lisis de uso:** Trackear queries populares para mejorar sin√≥nimos y sugerencias

### Definici√≥n de Hecho (DoD)

- [ ] API REST implementada con endpoints para search, autocomplete, saved searches
- [ ] Elasticsearch configurado con mappings personalizados, analyzers y synonym filters
- [ ] Tests unitarios para query parser y scoring algorithm (>80% cobertura)
- [ ] Tests de integraci√≥n con dataset real de 10,000+ candidatos
- [ ] Performance testing: <2s para b√∫squedas en 100k candidatos (p95)
- [ ] UI implementada con campo de b√∫squeda, filtros laterales, resultados paginados, y opci√≥n de guardar b√∫squeda
- [ ] Documentaci√≥n de API con ejemplos de queries complejas
- [ ] M√©tricas de relevancia evaluadas con usuarios reales (NDCG > 0.7)
- [ ] Logs de queries para an√°lisis de uso y mejora continua
- [ ] Aprobado por Product Owner con demos de b√∫squedas complejas

### Prioridad: Alta
### Estimaci√≥n Inicial: L (2-3 semanas)
### Dependencias:
- US-001 (Parseo de CV) - necesita base de datos poblada con candidatos
- Elasticsearch configurado y operacional
- Modelo de datos CANDIDATE y CANDIDATE_SKILL completo

---

## US-003: Publicaci√≥n Multi-Canal de Ofertas de Trabajo

**Como** Recruiter
**Quiero** publicar una oferta de trabajo en m√∫ltiples plataformas externas (LinkedIn, Indeed, Glassdoor) con un solo clic
**Para** maximizar el alcance de mis vacantes sin tener que publicar manualmente en cada plataforma, ahorrando tiempo y garantizando consistencia

### Criterios de Aceptaci√≥n

- [ ] Desde la vista de detalle de un Job (estado "Approved"), el Recruiter puede seleccionar m√∫ltiples canales de publicaci√≥n mediante checkboxes (LinkedIn, Indeed, Glassdoor, sitio web corporativo)
- [ ] El sistema adapta autom√°ticamente el formato de la oferta seg√∫n los requisitos de cada plataforma (l√≠mites de caracteres, campos obligatorios, categor√≠as)
- [ ] Antes de publicar, el sistema muestra una vista previa de c√≥mo se ver√° la oferta en cada plataforma seleccionada
- [ ] Al confirmar publicaci√≥n, el sistema publica en paralelo en todos los canales seleccionados y muestra un indicador de progreso
- [ ] Si alguna publicaci√≥n falla, el sistema contin√∫a con las dem√°s, notifica el error con detalles espec√≠ficos, y permite reintentar individualmente
- [ ] Cada publicaci√≥n exitosa genera un registro en tabla JOB_POSTING con platform_job_id, URL directa, y timestamp
- [ ] El sistema configura autom√°ticamente tracking UTM para cada canal (source, medium, campaign) para attribution
- [ ] El Recruiter puede ver el estado de todas las publicaciones activas en un panel consolidado con m√©tricas (views, applies por plataforma)
- [ ] El sistema permite despublicar ofertas de todos los canales simult√°neamente o individualmente

### Notas T√©cnicas

- **Arquitectura:** Integrations Service (Node.js) con adaptadores por plataforma (Strategy pattern)
- **APIs externas:**
  - LinkedIn Jobs API (requiere partnership)
  - Indeed API (API key requerida)
  - Glassdoor API (OAuth 2.0)
  - Web corporativo: endpoint interno
- **Manejo de rate limits:** Implementar exponential backoff y queue-based publishing para respetar l√≠mites de API
- **Formato de adaptaci√≥n:** Mapper por plataforma que transforma Job model a formato espec√≠fico (validaci√≥n con JSON schemas)
- **Preview generation:** Templates HTML/CSS responsive que simulan el rendering de cada plataforma
- **Tracking UTM:** Patr√≥n est√°ndar: ?utm_source={platform}&utm_medium=job_board&utm_campaign={job_id}
- **Error handling:** Circuit breaker pattern para evitar cascading failures, logs detallados por plataforma
- **Webhooks:** Configurar webhooks de plataformas para recibir notificaciones de applies directamente
- **Credenciales:** Almacenar API keys y tokens en AWS Secrets Manager o HashiCorp Vault
- **Retry logic:** Queue con reintentos autom√°ticos (3 intentos con backoff de 1min, 5min, 15min)
- **Bidirectional sync:** Job de sincronizaci√≥n cada hora para actualizar m√©tricas (views, applies) desde plataformas

### Definici√≥n de Hecho (DoD)

- [ ] Integrations Service implementado con adaptadores para m√≠nimo 3 plataformas (LinkedIn, Indeed, Glassdoor)
- [ ] Endpoints REST: POST /jobs/{id}/publish, DELETE /jobs/{id}/unpublish, GET /jobs/{id}/postings
- [ ] Tests unitarios para cada adapter con >80% cobertura
- [ ] Tests de integraci√≥n con APIs reales en entorno sandbox/staging
- [ ] Tests end-to-end simulando publicaci√≥n completa y manejo de errores
- [ ] UI implementada: modal de selecci√≥n de canales, previews, indicador de progreso, panel de estado de publicaciones
- [ ] Documentaci√≥n t√©cnica: gu√≠a de integraci√≥n por plataforma, troubleshooting com√∫n, configuraci√≥n de API keys
- [ ] Monitoreo configurado: alertas para fallos de publicaci√≥n, m√©tricas de success rate por plataforma
- [ ] Logs estructurados con correlation IDs para debugging
- [ ] Demo exitosa con publicaci√≥n real en 3 plataformas
- [ ] Aprobado por Product Owner

### Prioridad: Alta
### Estimaci√≥n Inicial: XL (3-4 semanas)
### Dependencias:
- Modelo de datos JOB y JOB_POSTING implementado
- Partnerships o API keys obtenidos para plataformas externas
- Integrations Service base implementado

---

## US-004: Flujo de Aprobaci√≥n de Ofertas de Trabajo

**Como** Hiring Manager
**Quiero** revisar y aprobar/rechazar ofertas de trabajo creadas por Recruiters antes de que se publiquen
**Para** garantizar que las descripciones y requisitos sean precisos, est√©n alineados con las necesidades del equipo y cumplan con pol√≠ticas de la empresa

### Criterios de Aceptaci√≥n

- [ ] Cuando un Recruiter completa la creaci√≥n de un Job y lo marca como "Ready for Approval", el sistema cambia autom√°ticamente el estado a "Pending Approval" y notifica al Hiring Manager asignado
- [ ] El Hiring Manager recibe una notificaci√≥n (email + in-app) con link directo al Job para revisi√≥n
- [ ] En la vista de aprobaci√≥n, el HM puede ver todos los detalles del Job: t√≠tulo, descripci√≥n completa, requisitos (required_skills y nice_to_have_skills), ubicaci√≥n, salary range, tipo de empleo, departamento
- [ ] El HM puede realizar una de tres acciones: (1) Aprobar, (2) Rechazar con comentarios obligatorios, (3) Solicitar cambios con comentarios espec√≠ficos
- [ ] Si el HM selecciona "Solicitar cambios", puede agregar comentarios inline en campos espec√≠ficos y @mencionar al Recruiter
- [ ] Al aprobar, el Job cambia a estado "Approved" y se habilita el bot√≥n de "Publish" para el Recruiter
- [ ] Al rechazar, el Job cambia a estado "Rejected", se notifica al Recruiter con los comentarios, y el Job no puede publicarse
- [ ] Al solicitar cambios, el Job vuelve a estado "Draft", se notifica al Recruiter, quien puede editar y re-enviar para aprobaci√≥n
- [ ] Todo el historial de aprobaciones/rechazos/cambios se registra en una tabla APPROVAL_HISTORY con timestamps y comentarios
- [ ] El sistema muestra un timeline visual con todas las transiciones de estado del Job

### Notas T√©cnicas

- **Estado del Job:** Agregar estados "Pending Approval", "Changes Requested", "Rejected" al enum de status en modelo JOB
- **Modelo de aprobaci√≥n:** Tabla APPROVAL_HISTORY (job_id, approver_id, action [approved/rejected/changes_requested], comments, created_at)
- **Notificaciones:** Usar Notifications Service con templates para emails y in-app notifications
- **Comentarios inline:** Usar estructura JSON en campo comments con formato {field: "description", comment: "Necesita m√°s detalle t√©cnico"}
- **Menciones:** Parser de @username en comentarios, notificaciones autom√°ticas a usuarios mencionados
- **Permisos:** Solo Hiring Managers asignados al Job pueden aprobar (validar RBAC en backend)
- **SLA tracking:** Opcional - trackear tiempo desde "Pending Approval" hasta decisi√≥n para m√©tricas de eficiencia
- **Email templates:** Dise√±ar templates responsive con botones de acci√≥n (Approve/Review) que abren directamente el Job en LTI
- **Audit trail:** Todos los cambios de estado emitir eventos para logging centralizado
- **Workflow engine:** Considerar uso de biblioteca de state machine (xstate o similar) para gesti√≥n robusta de transiciones

### Definici√≥n de Hecho (DoD)

- [ ] Modelo de datos actualizado con nuevos estados y tabla APPROVAL_HISTORY
- [ ] API endpoints: POST /jobs/{id}/submit-for-approval, POST /jobs/{id}/approve, POST /jobs/{id}/reject, POST /jobs/{id}/request-changes
- [ ] Tests unitarios para l√≥gica de state transitions con >80% cobertura
- [ ] Tests de integraci√≥n para flujo completo: crear ‚Üí enviar a aprobaci√≥n ‚Üí aprobar/rechazar
- [ ] Tests de permisos: usuarios sin rol HM no pueden aprobar
- [ ] UI implementada: vista de aprobaci√≥n con detalles completos, botones de acci√≥n, campo de comentarios, timeline de historial
- [ ] Notificaciones configuradas y testeadas (email + in-app)
- [ ] Documentaci√≥n de estados y transiciones permitidas
- [ ] Logs de auditor√≠a verificados en entorno de staging
- [ ] Demo exitosa con flujo completo de aprobaci√≥n
- [ ] Aprobado por Product Owner

### Prioridad: Media
### Estimaci√≥n Inicial: M (1-2 semanas)
### Dependencias:
- Modelo de datos JOB base implementado
- Notifications Service operacional
- Sistema de permisos RBAC funcional
- UI de creaci√≥n de Jobs completa

---

## US-005: Screening Automatizado con Scoring Predictivo

**Como** Recruiter
**Quiero** que el sistema eval√∫e autom√°ticamente cada candidato que aplica y le asigne un Match Score (0-100) basado en qu√© tan bien encaja con los requisitos del puesto
**Para** priorizar r√°pidamente a los mejores candidatos y reducir el tiempo dedicado a screening manual de CVs no relevantes

### Criterios de Aceptaci√≥n

- [ ] Cuando un candidato aplica a un Job (nuevo APPLICATION creado), el sistema autom√°ticamente dispara el flujo de screening en menos de 5 segundos
- [ ] El AI Screening Service analiza el perfil del candidato vs requisitos del Job evaluando: match de habilidades t√©cnicas (required y nice-to-have), a√±os de experiencia relevante, nivel educativo, fit de industria/sector, se√±ales de calidad (empresas reconocidas, progresi√≥n de carrera)
- [ ] El sistema genera un Match Score (n√∫mero entero 0-100) usando modelo de ML entrenado con datos hist√≥ricos de contrataciones exitosas
- [ ] El score se almacena en el campo match_score de la tabla APPLICATION junto con un breakdown detallado en JSON (ai_analysis: {skill_match: 85, experience_match: 90, education_match: 75, ...})
- [ ] En el dashboard del Recruiter, los candidatos se ordenan autom√°ticamente por Match Score descendente al abrir un Job
- [ ] Candidatos con score >80 reciben autom√°ticamente la etiqueta "High Priority" y generan una notificaci√≥n al Recruiter
- [ ] El sistema muestra visualmente el desglose del score con indicadores por categor√≠a (skills: 85/100, experiencia: 90/100, etc.)
- [ ] Si el modelo tiene baja confianza (<50% confidence), el sistema marca el candidato para revisi√≥n manual
- [ ] El Recruiter puede dar feedback en el score (thumbs up/down) que se usa para reentrenamiento del modelo

### Notas T√©cnicas

- **Modelo de ML:** XGBoost o LightGBM entrenado con dataset hist√≥rico (m√≠nimo 5,000 aplicaciones con outcome: hired/rejected)
- **Features del modelo:**
  - Skill match percentage (jaccard similarity entre required_skills y candidate_skills)
  - Semantic skill match (embeddings similarity usando BERT)
  - Years of experience delta (actual vs requerido)
  - Education level score (PhD:5, Master:4, Bachelor:3, etc.)
  - Company quality score (basado en ranking de empresas: FAANG=5, startup conocido=4, etc.)
  - Career trajectory (promotions, title progression)
  - Industry overlap
- **Training pipeline:** Pipeline automatizado en Python con MLflow para versionado de modelos
- **Model serving:** Modelo desplegado en SageMaker o contenedor Docker con API REST
- **Feature store:** PostgreSQL table con features pre-computadas para serving r√°pido
- **Umbral de confianza:** Calibrar modelo para output de confidence score, marcar para revisi√≥n si <50%
- **Feedback loop:** Tabla SCREENING_FEEDBACK (application_id, predicted_score, recruiter_feedback, actual_outcome) para reentrenamiento
- **Reentrenamiento:** Job semanal o cada 10k aplicaciones nuevas para reentrenar con datos frescos
- **A/B testing:** Framework para probar nuevas versiones del modelo vs modelo actual (champion/challenger)
- **Explicabilidad:** Usar SHAP values para explicar por qu√© un candidato recibi√≥ cierto score
- **Performance:** Scoring debe completarse en <10 segundos para 95% de los casos

### Definici√≥n de Hecho (DoD)

- [ ] Modelo de ML entrenado con AUC-ROC >0.75 en test set
- [ ] AI Screening Service implementado con endpoint POST /screen-candidate
- [ ] Pipeline de features implementado para extraer y calcular todas las features necesarias
- [ ] Tests unitarios para c√°lculo de features con >80% cobertura
- [ ] Tests de integraci√≥n con dataset real de 1000+ candidatos
- [ ] Performance testing: screening de 100 candidatos en paralelo <10s cada uno
- [ ] UI actualizada: vista de candidatos ordenada por score, breakdown visual del score, bot√≥n de feedback
- [ ] Modelo deployado en producci√≥n con versionado en MLflow
- [ ] Monitoring configurado: latencia de scoring, distribuci√≥n de scores, feedback rate
- [ ] Documentaci√≥n t√©cnica: arquitectura del modelo, features utilizadas, proceso de reentrenamiento
- [ ] Logs estructurados con scores y breakdown para an√°lisis
- [ ] Demo con candidatos reales mostrando scoring preciso
- [ ] Aprobado por Product Owner

### Prioridad: Alta
### Estimaci√≥n Inicial: XL (3-4 semanas)
### Dependencias:
- US-001 (Parseo de CV) - necesita datos estructurados de candidatos
- Modelo de datos APPLICATION con campo match_score y ai_analysis (JSON)
- Dataset hist√≥rico de aplicaciones etiquetadas para entrenamiento
- Infraestructura de ML (MLflow, SageMaker o equivalente)

---

## US-006: Etiquetado Inteligente Autom√°tico de Candidatos

**Como** Recruiter
**Quiero** que el sistema asigne autom√°ticamente etiquetas descriptivas a cada candidato (ej: "Top Performer", "Missing Skills: Python", "Career Changer")
**Para** filtrar y segmentar r√°pidamente candidatos por caracter√≠sticas clave sin tener que leer cada CV completo

### Criterios de Aceptaci√≥n

- [ ] Cuando se completa el screening de un candidato, el sistema autom√°ticamente genera y asigna etiquetas relevantes basadas en reglas de negocio y an√°lisis de IA
- [ ] El sistema soporta las siguientes etiquetas predefinidas:
  - "Top Performer" (score >85 + experiencia en empresas top-tier)
  - "High Potential" (score 70-84 + progresi√≥n de carrera r√°pida)
  - "Career Changer" (cambio significativo de industria/rol en √∫ltimos 2 a√±os)
  - "Overqualified" (a√±os de experiencia >150% del requerido + senior titles)
  - "Missing Skills: X, Y" (skills cr√≠ticos ausentes del perfil)
  - "Hot Lead" (score >80 + aplicaci√≥n reciente <48h)
  - "Culture Fit Risk" (alta rotaci√≥n laboral: >3 cambios en √∫ltimos 2 a√±os)
  - "Local Talent" (ubicaci√≥n match exacto con Job location)
  - "Relocation Required" (ubicaci√≥n diferente a Job location)
- [ ] Las etiquetas se almacenan en el campo tags (JSON array) de la tabla APPLICATION
- [ ] En la UI, las etiquetas se muestran como badges de colores junto al nombre del candidato
- [ ] El Recruiter puede filtrar la lista de candidatos por una o m√∫ltiples etiquetas usando un filtro lateral
- [ ] El Recruiter puede agregar etiquetas personalizadas manualmente (custom tags)
- [ ] El Recruiter puede eliminar etiquetas auto-generadas que considere incorrectas
- [ ] Las etiquetas se actualizan autom√°ticamente si cambia informaci√≥n del candidato (ej: actualizaci√≥n de CV)
- [ ] El sistema muestra un tooltip explicativo al hacer hover sobre cada etiqueta indicando por qu√© fue asignada

### Notas T√©cnicas

- **Motor de reglas:** Implementar rule engine con l√≥gica configurable (puede usar biblioteca como json-rules-engine o implementaci√≥n custom)
- **Reglas de negocio:** Definir reglas en formato JSON para f√°cil modificaci√≥n sin c√≥digo:
  ```json
  {
    "tag": "Top Performer",
    "conditions": {
      "all": [
        {"fact": "match_score", "operator": "greaterThan", "value": 85},
        {"fact": "company_tier", "operator": "in", "value": ["tier1", "tier2"]}
      ]
    }
  }
  ```
- **Skill gap detection:** Comparar required_skills del Job con candidate_skills, listar diferencias
- **Career trajectory analysis:** Calcular velocidad de progresi√≥n basado en cambios de t√≠tulo y seniority
- **Company tier classification:** Mantener diccionario de empresas clasificadas por tier (tier1: FAANG, unicorns; tier2: conocidas; tier3: resto)
- **Rotaci√≥n laboral:** Calcular n√∫mero de empleos en ventana de tiempo desde work history
- **Geolocalizaci√≥n:** Usar geocoding para calcular distancia entre candidate location y job location
- **Custom tags:** Almacenar en mismo array JSON con flag {tag: "Custom Tag", is_custom: true}
- **Performance:** Tag generation debe ejecutarse en <2 segundos como parte del screening workflow
- **Color coding:** Definir esquema de colores consistente (verde: positivo, rojo: warning, azul: neutral, amarillo: atenci√≥n)
- **Auditor√≠a:** Registrar cuando se crean/eliminan tags y por qui√©n (AUTO_SYSTEM vs USER_ID)

### Definici√≥n de Hecho (DoD)

- [ ] Rule engine implementado con m√≠nimo 9 reglas predefinidas
- [ ] L√≥gica de tagging integrada en AI Screening Service workflow
- [ ] Tests unitarios para cada regla de tagging con >80% cobertura
- [ ] Tests de integraci√≥n con candidatos de ejemplo cubriendo todos los tipos de tags
- [ ] UI actualizada: badges visuales por candidato, filtro lateral multi-select, tooltips explicativos
- [ ] API endpoints: GET /applications/{id}/tags, POST /applications/{id}/tags (agregar custom), DELETE /applications/{id}/tags/{tag}
- [ ] Documentaci√≥n de reglas de negocio con ejemplos
- [ ] Configuration file para reglas en formato JSON editable sin deployment
- [ ] Performance testing: tagging de 1000 candidatos en <5min
- [ ] Logs de tags asignados para an√°lisis y mejora de reglas
- [ ] Demo con candidatos diversos mostrando tags correctos
- [ ] Aprobado por Product Owner

### Prioridad: Media
### Estimaci√≥n Inicial: M (1-2 semanas)
### Dependencias:
- US-005 (Screening Automatizado) - el tagging se ejecuta post-screening
- Modelo de datos APPLICATION con campo tags (JSON)
- Diccionario de empresas clasificadas por tier
- L√≥gica de c√°lculo de skills gap implementada

---

## US-007: Programaci√≥n Autom√°tica de Entrevistas con Integraci√≥n de Calendarios

**Como** Recruiter
**Quiero** que el sistema encuentre autom√°ticamente horarios disponibles en los calendarios de los entrevistadores y el candidato, y programe las entrevistas sin coordinaci√≥n manual
**Para** eliminar el intercambio tedioso de emails de "¬øcu√°ndo puedes?" y reducir el tiempo de coordinaci√≥n de entrevistas en 80%

### Criterios de Aceptaci√≥n

- [ ] Desde la vista del candidato, el Recruiter puede hacer clic en "Schedule Interview" y seleccionar el tipo de entrevista (Phone/Technical/Manager/Panel) y los entrevistadores participantes (1-n usuarios)
- [ ] El sistema consulta autom√°ticamente los calendarios de todos los participantes v√≠a integraci√≥n con Google Calendar y/o Outlook
- [ ] El sistema identifica slots de tiempo comunes disponibles en los pr√≥ximos 7-14 d√≠as (configurable) respetando horario laboral (9am-6pm default, configurable)
- [ ] El sistema sugiere 3-5 opciones de horarios √≥ptimos considerando: disponibilidad de todos, minimizar tiempo de espera, evitar slots muy tempranos/tard√≠os
- [ ] El Recruiter selecciona uno de los slots sugeridos o puede buscar manualmente otra fecha
- [ ] Al confirmar, el sistema autom√°ticamente: (1) crea eventos en los calendarios de todos los participantes, (2) genera link de videollamada (Zoom/Teams), (3) env√≠a invitaciones por email con agenda, link de video, perfil del candidato, y gu√≠a de entrevista
- [ ] El sistema crea un registro en tabla INTERVIEW con status "Scheduled" y todos los detalles (participants, scheduled_time, video_link, etc.)
- [ ] El sistema env√≠a recordatorios autom√°ticos a todos los participantes 24 horas y 1 hora antes de la entrevista
- [ ] Si hay conflicto (alguien cancela su disponibilidad), el sistema detecta y notifica al Recruiter sugiriendo reprogramar

### Notas T√©cnicas

- **Integraciones de calendario:**
  - Google Calendar API (OAuth 2.0, scopes: calendar.readonly + calendar.events)
  - Microsoft Graph API para Outlook (OAuth 2.0)
- **Availability detection:** FreeBusy query para obtener slots ocupados, calcular slots libres intersectando calendarios de todos
- **Timezone handling:** Usar biblioteca moment-timezone o date-fns-tz, almacenar timestamps en UTC, mostrar en timezone del usuario
- **Video conferencing:**
  - Zoom API para crear meetings programados (requiere Zoom account)
  - Microsoft Teams API para crear Teams meetings
  - Almacenar video_link en tabla INTERVIEW
- **Algoritmo de sugerencia:** Scoring de slots considerando:
  - Preferencia por bloques de ma√±ana (score m√°s alto)
  - Minimizar d√≠as de espera (score m√°s alto para fechas m√°s cercanas)
  - Evitar first/last hour del d√≠a
  - Buffer time si entrevistadores tienen meetings antes/despu√©s
- **Email invitations:** Usar formato iCal (.ics) para compatibilidad universal con clients de email
- **Reminder scheduling:** Job scheduler (node-cron o AWS EventBridge) para enviar emails/notificaciones en tiempos espec√≠ficos
- **Conflict detection:** Webhook de Google/Outlook para recibir notificaciones de cambios en calendarios, polling cada hora como fallback
- **Retry logic:** Si un slot se llena antes de confirmar, ofrecer inmediatamente siguientes opciones
- **Permisos:** Usuarios deben authorizar acceso a calendario en su perfil (OAuth flow)
- **Multi-timezone:** Si participantes en diferentes zonas horarias, mostrar en timezone de cada uno

### Definici√≥n de Hecho (DoD)

- [ ] Integraci√≥n con Google Calendar funcionando: lectura de disponibilidad + creaci√≥n de eventos
- [ ] Integraci√≥n con Microsoft Outlook funcionando: lectura de disponibilidad + creaci√≥n de eventos
- [ ] Integraci√≥n con Zoom o Teams para generaci√≥n de video links
- [ ] API endpoints: POST /interviews/schedule, GET /interviews/{id}, PUT /interviews/{id}/reschedule, DELETE /interviews/{id}
- [ ] Tests unitarios para algoritmo de slot matching con >80% cobertura
- [ ] Tests de integraci√≥n con calendarios mock y reales en sandbox
- [ ] Tests de manejo de timezones con participantes en diferentes zonas
- [ ] UI implementada: modal de scheduling con selecci√≥n de tipo y participantes, visualizaci√≥n de slots sugeridos en formato calendario, confirmaci√≥n
- [ ] Email templates para invitaciones y recordatorios dise√±ados y testeados
- [ ] Job scheduler configurado para recordatorios autom√°ticos
- [ ] Documentaci√≥n de OAuth setup y permisos necesarios
- [ ] Logs detallados de todas las operaciones de calendario para debugging
- [ ] Performance testing: scheduling de entrevista completa en <15 segundos
- [ ] Demo exitosa coordinando entrevista real con m√∫ltiples participantes
- [ ] Aprobado por Product Owner

### Prioridad: Alta
### Estimaci√≥n Inicial: XL (3-4 semanas)
### Dependencias:
- Modelo de datos INTERVIEW, INTERVIEW_PARTICIPANT implementado
- Cuentas de desarrollo/sandbox para Google Calendar, Outlook, Zoom/Teams
- OAuth infrastructure para manejo de tokens de usuarios
- Email service operacional
- Scheduler service configurado

---

## US-008: Evaluaci√≥n Estructurada con Scorecards

**Como** Interviewer
**Quiero** completar un scorecard estructurado despu√©s de cada entrevista con ratings por dimensi√≥n y comentarios cualitativos
**Para** proporcionar feedback consistente y comparable que ayude al equipo a tomar decisiones de contrataci√≥n basadas en datos

### Criterios de Aceptaci√≥n

- [ ] Despu√©s de que una entrevista finaliza (status cambia a "Completed"), cada Interviewer recibe una notificaci√≥n para completar su scorecard
- [ ] El scorecard presenta las dimensiones de evaluaci√≥n predefinidas seg√∫n el tipo de entrevista (ej: Technical ‚Üí "Problem Solving", "Code Quality", "Communication"; Manager ‚Üí "Culture Fit", "Motivation", "Leadership Potential")
- [ ] Para cada dimensi√≥n, el Interviewer asigna un rating en escala de 1-5 estrellas o Likert (Poor/Fair/Good/Very Good/Excellent)
- [ ] El scorecard incluye secciones obligatorias para: comentarios cualitativos generales (min 50 caracteres), concerns espec√≠ficos (optional), highlights del candidato (optional), y recomendaci√≥n final (Strong Yes / Yes / Maybe / No / Strong No)
- [ ] El sistema valida que todos los campos obligatorios est√©n completos antes de permitir submit
- [ ] Al guardar el scorecard como "Draft", el Interviewer puede volver m√°s tarde para completarlo
- [ ] Al submitir el scorecard (status "Submitted"), este se registra en tabla SCORECARD con timestamp y queda visible para Hiring Manager y Recruiters
- [ ] El sistema calcula autom√°ticamente un score promedio ponderado por dimensi√≥n para el candidato agregando todos los scorecards
- [ ] Si el scorecard no se completa en 24 horas, el sistema env√≠a recordatorio al Interviewer

### Notas T√©cnicas

- **Templates de scorecard:** Tabla INTERVIEW_TEMPLATE con campo scorecard_template (JSON) definiendo dimensiones por tipo:
  ```json
  {
    "dimensions": [
      {"name": "Problem Solving", "weight": 0.3, "scale": "1-5"},
      {"name": "Code Quality", "weight": 0.3, "scale": "1-5"},
      {"name": "Communication", "weight": 0.2, "scale": "1-5"},
      {"name": "Culture Fit", "weight": 0.2, "scale": "1-5"}
    ],
    "required_fields": ["qualitative_feedback", "recommendation"]
  }
  ```
- **Modelo de datos:** Tabla SCORECARD con campos interviewer_id, interview_id, ratings (JSON), qualitative_feedback (text), concerns (text), highlights (text), recommendation (enum), status (draft/submitted), submitted_at
- **Validaci√≥n:** Backend validation que todos los campos required del template est√©n presentes
- **Peso de dimensiones:** Usar weight para calcular score ponderado agregado
- **Permisos:** Solo participantes del interview pueden crear scorecard para ese interview
- **Notifications:** Trigger autom√°tico post-interview para enviar email/in-app notification con link directo al scorecard
- **Reminders:** Job scheduler que chequea scorecards pendientes y env√≠a recordatorios
- **Draft auto-save:** Auto-save cada 30 segundos mientras el usuario escribe (localStorage o API call)
- **Anonymization (opcional):** Opci√≥n de anonimizar scorecards durante evaluaci√≥n para reducir bias (mostrar solo ratings sin nombres)
- **Audit trail:** Registrar created_at, updated_at, submitted_at para tracking de tiempos de respuesta
- **Metrics:** Trackear completion rate y tiempo promedio para completar scorecards

### Definici√≥n de Hecho (DoD)

- [ ] Modelo de datos SCORECARD y INTERVIEW_TEMPLATE implementado
- [ ] API endpoints: POST /scorecards (create draft), PUT /scorecards/{id} (update), POST /scorecards/{id}/submit
- [ ] Tests unitarios para validaci√≥n de campos y c√°lculo de scores ponderados con >80% cobertura
- [ ] Tests de integraci√≥n: flujo completo desde interview completed ‚Üí notification ‚Üí scorecard submission
- [ ] UI implementada: formulario de scorecard con ratings interactivos (estrellas/slider), text areas, dropdown de recomendaci√≥n, indicador de progreso, botones save draft/submit
- [ ] Templates predefinidos para m√≠nimo 3 tipos de entrevista (Technical, Manager, Phone Screen)
- [ ] Notifications configuradas: post-interview + reminder 24h
- [ ] Auto-save functionality implementada y testeada
- [ ] Documentaci√≥n de estructura de templates y gu√≠a para crear custom templates
- [ ] Performance testing: rendering de scorecard y submit en <2 segundos
- [ ] Demo con diferentes tipos de scorecards
- [ ] Aprobado por Product Owner

### Prioridad: Alta
### Estimaci√≥n Inicial: M (1-2 semanas)
### Dependencias:
- Modelo de datos INTERVIEW completo
- Notification Service operacional
- Sistema de permisos validando participantes de interview

---

## US-009: Evaluaci√≥n Colaborativa en Tiempo Real

**Como** Hiring Manager
**Quiero** discutir candidatos con mi equipo usando comentarios en tiempo real, menciones, y threads de discusi√≥n dentro de la plataforma
**Para** centralizar toda la conversaci√≥n sobre candidatos en un solo lugar y tomar decisiones m√°s r√°pidas sin depender de emails o Slack

### Criterios de Aceptaci√≥n

- [ ] Desde la vista de detalle de cualquier candidato (APPLICATION), los usuarios autorizados (Recruiter, HM, Interviewers) pueden agregar comentarios en un thread de discusi√≥n
- [ ] El sistema de comentarios soporta @menciones de otros usuarios (ej: "@john ¬øqu√© opinas de las habilidades de React de este candidato?")
- [ ] Cuando un usuario es @mencionado, recibe una notificaci√≥n inmediata (in-app + email opcional) con link directo al comentario
- [ ] Los comentarios se pueden marcar como "Internal Only" (solo visibles para el equipo) o "Shareable" (pueden incluirse en reports)
- [ ] Los comentarios se muestran en orden cronol√≥gico con timestamp, avatar del autor, y nombre
- [ ] Los usuarios pueden editar sus propios comentarios dentro de 15 minutos de publicados (indicador "edited" visible)
- [ ] Los usuarios pueden responder a comentarios espec√≠ficos creando threads anidados
- [ ] El sistema muestra indicador de "X est√° escribiendo..." cuando otro usuario est√° componiendo un comentario en tiempo real
- [ ] Los nuevos comentarios aparecen autom√°ticamente sin necesidad de refresh (WebSockets o polling)
- [ ] El Hiring Manager puede "resolver" threads de discusi√≥n cuando la pregunta/issue est√° cerrado
- [ ] En el dashboard del candidato, se muestra un badge con el n√∫mero de comentarios no le√≠dos

### Notas T√©cnicas

- **Real-time communication:** WebSockets (Socket.io o similar) para notificaciones en tiempo real de nuevos comentarios y typing indicators
- **Modelo de datos:** Tabla COMMENT con campos application_id, user_id, content (text), mentions (JSON array de user_ids), is_internal (boolean), parent_comment_id (para threads), is_resolved (boolean), created_at, updated_at, edited (boolean)
- **Menciones parsing:** Regex para detectar @username en texto, reemplazar con links y almacenar IDs en campo mentions
- **Notifications:** Trigger autom√°tico cuando se crea comment con mentions ‚Üí enviar notificaci√≥n a usuarios mencionados
- **Permisos:** Solo usuarios con acceso al APPLICATION (misma company, asignados al job) pueden ver/crear comentarios
- **WebSocket rooms:** Crear room por application_id, usuarios join al abrir vista de candidato
- **Typing indicator:** Emit evento "typing" via WebSocket con debounce de 2 segundos
- **Polling fallback:** Si WebSocket falla, polling cada 10 segundos para fetch nuevos comentarios
- **Edici√≥n:** Permitir UPDATE solo si current_time - created_at < 15min y user_id = comment.user_id
- **Threads anidados:** Usar parent_comment_id para estructura de √°rbol, limitar a 2 niveles de profundidad
- **Markdown support (opcional):** Permitir formatting b√°sico (bold, italic, links) con librer√≠a markdown-it
- **Unread tracking:** Tabla USER_COMMENT_READ (user_id, comment_id, read_at) para tracking de le√≠dos
- **Performance:** Paginar comentarios si >100 para un candidato (cargar los 20 m√°s recientes inicialmente)

### Definici√≥n de Hecho (DoD)

- [ ] Modelo de datos COMMENT y USER_COMMENT_READ implementado
- [ ] WebSocket server configurado con rooms por application
- [ ] API endpoints: GET /applications/{id}/comments, POST /applications/{id}/comments, PUT /comments/{id}, POST /comments/{id}/resolve
- [ ] Tests unitarios para parsing de menciones y validaciones con >80% cobertura
- [ ] Tests de integraci√≥n: flujo completo de crear comment ‚Üí mention ‚Üí notification
- [ ] Tests de real-time: verificar que m√∫ltiples clientes reciben updates inmediatos
- [ ] UI implementada: thread de comentarios con avatars, timestamps, bot√≥n reply, indicador edited, typing indicator, badges de unread
- [ ] Funcionalidad de @mention con autocomplete dropdown de usuarios
- [ ] Notifications in-app y email configuradas para mentions
- [ ] Documentaci√≥n de arquitectura WebSocket y manejo de reconexi√≥n
- [ ] Performance testing: 100 usuarios concurrentes en un application sin latencia >500ms
- [ ] Demo con m√∫ltiples usuarios comentando en tiempo real
- [ ] Aprobado por Product Owner

### Prioridad: Media
### Estimaci√≥n Inicial: L (2-3 semanas)
### Dependencias:
- Modelo de datos APPLICATION base
- WebSocket infrastructure configurada (Socket.io, Redis para pub/sub si multi-server)
- Notification Service operacional
- Sistema de permisos RBAC

---

## US-010: Vista Consolidada de Feedback de Entrevistas

**Como** Hiring Manager
**Quiero** ver todos los scorecards de entrevistas de un candidato agregados en una vista consolidada con ratings promedio, distribuci√≥n de recomendaciones y comentarios destacados
**Para** tener una visi√≥n hol√≠stica r√°pida de la evaluaci√≥n del candidato sin tener que leer cada scorecard individualmente

### Criterios de Aceptaci√≥n

- [ ] Desde la vista de detalle del candidato, existe una secci√≥n "Interview Feedback" que muestra todos los scorecards completados
- [ ] La vista consolidada muestra para cada dimensi√≥n evaluada: rating promedio (ej: "Problem Solving: 4.2/5"), ratings individuales por entrevistador con nombres, y gr√°fico de barras visual
- [ ] La distribuci√≥n de recomendaciones finales se muestra con un gr√°fico de torta o barras (ej: "2 Strong Yes, 1 Yes, 0 Maybe, 0 No, 0 Strong No")
- [ ] Los comentarios cualitativos de todos los scorecards se agregan en una secci√≥n con filtros para ver "All", "Highlights Only", o "Concerns Only"
- [ ] Los highlights y concerns se muestran agrupados en bullet points con el nombre del entrevistador al lado
- [ ] El sistema detecta y alerta visualmente si hay divergencias significativas en evaluaciones (ej: un "Strong Yes" y un "No" para el mismo candidato)
- [ ] El HM puede comparar visualmente al candidato actual vs otros candidatos del mismo Job mostrando score promedio general
- [ ] La vista incluye un timeline de todas las entrevistas con fechas, tipos, participantes y status de scorecards (completado/pendiente)
- [ ] El HM puede exportar el consolidated feedback a PDF para compartir con stakeholders

### Notas T√©cnicas

- **Agregaci√≥n de datos:** Query que join INTERVIEW ‚Üí SCORECARD para obtener todos los scorecards de un APPLICATION
- **C√°lculo de promedios:** Agregar ratings por dimensi√≥n usando AVG, considerar weights de dimensions si est√°n definidos
- **Detecci√≥n de divergencias:** L√≥gica que compara recommendations: si contiene "Strong Yes" Y ("No" O "Strong No") ‚Üí flag de divergencia
- **Gr√°ficos:** Usar biblioteca de charting (Chart.js, Recharts, o D3.js) para visualizaci√≥n de barras y tortas
- **Comparaci√≥n de candidatos:** Query adicional para obtener score promedio de todos los APPLICATION del mismo Job, ordenar, indicar posici√≥n del candidato actual
- **Export to PDF:** Usar biblioteca de generaci√≥n de PDF (Puppeteer para headless Chrome rendering, o jsPDF/PDFKit para server-side)
- **Performance:** Cachear c√°lculos agregados si el n√∫mero de scorecards es alto (Redis cache con invalidaci√≥n al agregar nuevo scorecard)
- **Responsive design:** Vista debe funcionar en desktop y tablet
- **Permisos:** Solo HM, Recruiter y Admin pueden ver vista consolidada
- **Audit trail:** Registrar cada vez que se exporta PDF (qui√©n, cu√°ndo, qu√© candidato)

### Definici√≥n de Hecho (DoD)

- [ ] Query de agregaci√≥n optimizada con √≠ndices apropiados (application_id, interview_id)
- [ ] API endpoint: GET /applications/{id}/consolidated-feedback
- [ ] Tests unitarios para l√≥gica de agregaci√≥n y detecci√≥n de divergencias con >80% cobertura
- [ ] Tests de integraci√≥n con dataset de m√∫ltiples scorecards
- [ ] UI implementada: secci√≥n de consolidated feedback con gr√°ficos de ratings, distribuci√≥n de recommendations, highlights/concerns agrupados, timeline de entrevistas, alert visual de divergencias
- [ ] Funcionalidad de comparaci√≥n con otros candidatos del Job
- [ ] Export to PDF funcional con formato profesional
- [ ] Documentaci√≥n de estructura de datos y c√°lculos
- [ ] Performance testing: rendering de vista con 10+ scorecards en <3 segundos
- [ ] Demo mostrando vista consolidada de candidato con m√∫ltiples entrevistas
- [ ] Aprobado por Product Owner

### Prioridad: Media
### Estimaci√≥n Inicial: M (1-2 semanas)
### Dependencias:
- US-008 (Scorecards) - necesita scorecards completos para agregar
- Modelo de datos SCORECARD, INTERVIEW
- Biblioteca de charting seleccionada e integrada
- Biblioteca de PDF generation configurada

---

## US-011: Pipeline Visual Kanban para Gesti√≥n de Candidatos

**Como** Recruiter
**Quiero** ver todos los candidatos de un Job organizados en un tablero Kanban visual por etapa del proceso (Applied ‚Üí Screening ‚Üí Interview ‚Üí Offer ‚Üí Hired)
**Para** tener visibilidad instant√°nea del estado del pipeline, identificar cuellos de botella, y mover candidatos entre etapas con drag-and-drop

### Criterios de Aceptaci√≥n

- [ ] Al abrir la vista de un Job, se muestra un tablero Kanban con columnas representando cada etapa del proceso: "Applied", "Screening", "Interview", "Offer", "Hired", "Rejected"
- [ ] Cada columna muestra tarjetas de candidatos (APPLICATION) con informaci√≥n resumida: nombre, foto, Match Score, top 3 skills, tags principales, y d√≠as en etapa actual
- [ ] El n√∫mero total de candidatos en cada columna se muestra en el header de la columna
- [ ] El Recruiter puede arrastrar y soltar tarjetas entre columnas para cambiar el current_stage de un APPLICATION
- [ ] Al mover una tarjeta a nueva etapa, el sistema muestra un modal pidiendo raz√≥n opcional del cambio (especialmente para moves a "Rejected")
- [ ] El cambio de etapa se registra autom√°ticamente en STATUS_HISTORY con timestamp, usuario que hizo el cambio, y raz√≥n
- [ ] Las tarjetas se pueden filtrar por tags, Match Score range, o b√∫squeda por nombre
- [ ] Las columnas se pueden colapsar para ahorrar espacio si contienen muchos candidatos
- [ ] El sistema muestra indicadores visuales de alertas: candidatos estancados >7 d√≠as en una etapa (badge amarillo), interviews pr√≥ximos en 24h (badge azul), high-priority candidates (badge verde)
- [ ] El pipeline se actualiza en tiempo real si otro usuario hace cambios (WebSocket o polling)

### Notas T√©cnicas

- **Librer√≠a UI:** Usar biblioteca de drag-and-drop (react-beautiful-dnd, dnd-kit, o SortableJS)
- **Modelo de datos:** Usar campo current_stage de APPLICATION como fuente de verdad, etapas como enum: Applied/Screening/Interview/Offer/Hired/Rejected
- **Queries optimizadas:** Index en (job_id, current_stage) para queries r√°pidas, eager loading de relationships necesarios (candidate, skills, tags)
- **Real-time updates:** WebSocket room por job_id, emit evento "application_moved" cuando cambia current_stage
- **Responsive design:** Kanban horizontal en desktop, puede cambiar a lista vertical con filtros en mobile
- **Virtualization:** Si columnas tienen >50 candidatos, usar virtual scrolling (react-window) para performance
- **Drag validation:** Backend debe validar que el move es permitido (ej: no se puede mover directo de Applied a Hired sin pasar por etapas intermedias, esto depende de business rules)
- **Status history:** Trigger autom√°tico en UPDATE de current_stage para insertar registro en STATUS_HISTORY
- **Modal de raz√≥n:** Obligatorio solo para moves a "Rejected", opcional para otros
- **C√°lculo de "d√≠as en etapa":** current_date - MAX(changed_at) de STATUS_HISTORY para current_stage
- **Alerts l√≥gica:** Query que calcula d√≠as en etapa, si >7 ‚Üí stale_alert, si tiene interview en pr√≥ximas 24h ‚Üí upcoming_interview_alert
- **Performance:** Rendering inicial del board completo debe ser <2 segundos para jobs con 200+ candidatos

### Definici√≥n de Hecho (DoD)

- [ ] UI Kanban implementada con drag-and-drop funcional
- [ ] API endpoints: GET /jobs/{id}/pipeline, PUT /applications/{id}/stage (con validaci√≥n y status history)
- [ ] Tests unitarios para l√≥gica de validaci√≥n de moves y c√°lculo de d√≠as en etapa con >80% cobertura
- [ ] Tests de integraci√≥n: flujo completo de drag candidato ‚Üí update stage ‚Üí registro en history
- [ ] Tests de performance: rendering de board con 200 candidatos en <2s
- [ ] WebSocket configurado para updates en tiempo real
- [ ] Modal de raz√≥n implementado con UX fluida
- [ ] Filtros laterales funcionales (tags, score range, name search)
- [ ] Badges de alerts implementados con colores apropiados
- [ ] Documentaci√≥n de business rules para validaci√≥n de moves
- [ ] Logs de todos los cambios de etapa para auditor√≠a
- [ ] Demo con Job real mostrando drag-and-drop y real-time updates
- [ ] Aprobado por Product Owner

### Prioridad: Alta
### Estimaci√≥n Inicial: L (2-3 semanas)
### Dependencias:
- Modelo de datos APPLICATION con campo current_stage y tabla STATUS_HISTORY
- WebSocket infrastructure (si se quiere real-time)
- Librer√≠a de drag-and-drop integrada en frontend
- UI components base (cards, badges, modals)

---

## US-012: Dashboard de M√©tricas de Reclutamiento en Tiempo Real

**Como** Hiring Manager o Admin
**Quiero** ver un dashboard ejecutivo con KPIs clave del proceso de reclutamiento (Time-to-Hire, Cost-per-Hire, funnel conversion, source effectiveness)
**Para** tomar decisiones basadas en datos, identificar cuellos de botella, y medir la efectividad de nuestras estrategias de reclutamiento

### Criterios de Aceptaci√≥n

- [ ] El dashboard muestra los siguientes KPIs principales con visualizaciones:
  - **Time-to-Hire:** Promedio de d√≠as desde Applied hasta Hired (tendencia √∫ltimos 3/6/12 meses)
  - **Cost-per-Hire:** Costo total de reclutamiento / n√∫mero de hires (si se trackean costos)
  - **Offer Acceptance Rate:** % de ofertas aceptadas vs extendidas
  - **Funnel Conversion Rates:** % conversi√≥n en cada etapa (Applied‚ÜíScreening, Screening‚ÜíInterview, Interview‚ÜíOffer, Offer‚ÜíHired)
  - **Source Effectiveness:** N√∫mero de aplicaciones, hires, y quality score por fuente (LinkedIn, Indeed, Referral, etc.)
  - **Pipeline Health:** N√∫mero de candidatos activos por etapa, roles con pipeline d√©bil (<5 candidatos activos)
- [ ] Todos los KPIs se pueden filtrar por: rango de fechas, departamento, ubicaci√≥n, nivel de seniority, y job espec√≠fico
- [ ] Los gr√°ficos son interactivos: click en barra/segmento muestra drill-down con detalles (ej: click en "LinkedIn" muestra jobs con m√°s applies de LinkedIn)
- [ ] El dashboard se actualiza autom√°ticamente cada 5 minutos o tiene bot√≥n de "Refresh Now"
- [ ] Los KPIs muestran comparaci√≥n vs per√≠odo anterior (ej: "Time-to-Hire: 18 d√≠as, ‚Üì12% vs mes anterior")
- [ ] El usuario puede exportar el dashboard completo a PDF o cada gr√°fico individual a PNG/CSV
- [ ] Las m√©tricas de diversity (opcional) muestran distribuci√≥n de g√©nero, etnicidad si est√° disponible (cumpliendo con GDPR)
- [ ] El sistema alerta visualmente si alg√∫n KPI est√° fuera de rango esperado (ej: Time-to-Hire >30 d√≠as, Offer Acceptance <70%)

### Notas T√©cnicas

- **Arquitectura:** Analytics Service separado (Go para high performance) con base de datos optimizada para agregaciones
- **Data pipeline:** ETL job (Airflow, Luigi, o custom) que corre cada hora para pre-calcular m√©tricas y almacenar en tablas agregadas (ANALYTICS_METRICS)
- **Queries optimizadas:**
  - Time-to-Hire: AVG(hired_date - applied_date) WHERE current_stage = 'Hired' GROUP BY month
  - Funnel conversion: COUNT por stage / COUNT stage anterior
  - Source effectiveness: JOIN APPLICATION ‚Üí JOB_POSTING, GROUP BY platform
- **Visualizaciones:** Biblioteca de charting moderna (Recharts, Chart.js, Apache ECharts)
- **Tipos de gr√°ficos:** Line chart (tendencias), Bar chart (comparaciones), Pie/Donut (distribuciones), Funnel chart (conversi√≥n)
- **Real-time updates:** WebSocket para push de nuevas m√©tricas o polling cada 5min
- **Caching:** Redis cache para m√©tricas pre-calculadas (TTL 5min)
- **Export:** PDF usando Puppeteer/headless Chrome, CSV usando bibliotecas de data export
- **Drill-down:** Click handlers en gr√°ficos que hacen queries espec√≠ficos con filtros aplicados
- **Alerting:** Definir thresholds en config, evaluar en ETL job, emitir notificaciones si se exceden
- **Performance:** Dashboard completo debe cargar en <3 segundos, queries pre-computadas en tablas OLAP
- **Data retention:** Mantener datos hist√≥ricos m√≠nimo 24 meses para an√°lisis de tendencias
- **Permisos:** Solo roles Admin, Hiring Manager, y Recruiter con permisos especiales pueden ver analytics completos

### Definici√≥n de Hecho (DoD)

- [ ] Analytics Service implementado con endpoints para cada KPI
- [ ] ETL pipeline configurado para pre-c√°lculo de m√©tricas con job scheduler
- [ ] Tablas de agregaci√≥n (ANALYTICS_METRICS) con √≠ndices apropiados
- [ ] API endpoints: GET /analytics/time-to-hire, GET /analytics/funnel, GET /analytics/source-effectiveness, etc.
- [ ] Tests unitarios para l√≥gica de c√°lculo de m√©tricas con >80% cobertura
- [ ] Tests de integraci√≥n con dataset hist√≥rico
- [ ] UI dashboard implementada con todos los gr√°ficos, filtros interactivos, drill-down
- [ ] Funcionalidad de export a PDF y CSV testeada
- [ ] Sistema de alertas configurado con thresholds sensatos
- [ ] Documentaci√≥n de f√≥rmulas de c√°lculo de cada KPI
- [ ] Performance testing: dashboard completo carga en <3s con 10k+ applications
- [ ] Caching configurado y validado
- [ ] Demo mostrando dashboard completo con datos reales y drill-downs
- [ ] Aprobado por Product Owner

### Prioridad: Media
### Estimaci√≥n Inicial: XL (3-4 semanas)
### Dependencias:
- Modelo de datos completo (JOB, APPLICATION, STATUS_HISTORY, JOB_POSTING)
- Dataset hist√≥rico suficiente para m√©tricas significativas (m√≠nimo 3 meses de datos)
- Analytics Service infrastructure
- ETL/pipeline infrastructure (Airflow o similar)
- Biblioteca de charting integrada en frontend

---

## Resumen de Priorizaci√≥n

### Fase 1 - MVP (Alta Prioridad)
1. **US-001** - Parseo de CV (foundational)
2. **US-005** - Screening Automatizado (core value prop)
3. **US-011** - Pipeline Kanban (core UX)
4. **US-003** - Publicaci√≥n Multi-Canal (acquisition)
5. **US-007** - Scheduling Autom√°tico (time-saving)
6. **US-008** - Scorecards (evaluation)
7. **US-002** - B√∫squeda Sem√°ntica (talent reuse)

### Fase 2 - Maduraci√≥n (Media Prioridad)
8. **US-006** - Auto-Tagging (efficiency)
9. **US-004** - Aprobaci√≥n de Jobs (process)
10. **US-009** - Colaboraci√≥n Real-Time (teamwork)
11. **US-010** - Feedback Consolidado (decision quality)
12. **US-012** - Dashboard Analytics (insights)

---

## Notas Finales

**Convenciones INVEST aplicadas:**
- ‚úÖ **Independent:** Cada US puede desarrollarse en paralelo (con dependencias documentadas)
- ‚úÖ **Negotiable:** Criterios de aceptaci√≥n espec√≠ficos pero implementaci√≥n flexible
- ‚úÖ **Valuable:** Cada US entrega valor claro a un rol de usuario espec√≠fico
- ‚úÖ **Estimable:** T-shirt sizing basado en complejidad t√©cnica
- ‚úÖ **Small:** La mayor√≠a es M o L (1-3 semanas), XL solo para features muy complejas
- ‚úÖ **Testeable:** Criterios de aceptaci√≥n medibles y testables

**Pr√≥ximos Pasos:**
1. Validar priorizaci√≥n con stakeholders
2. Refinar estimaciones con equipo t√©cnico
3. Crear tickets en Jira/Linear con estas User Stories
4. Planificar sprints seg√∫n capacidad del equipo
5. Establecer m√©tricas de √©xito para cada US

---

**Documento generado:** 2025-01-09
**Versi√≥n:** 1.0
**Aprobaci√≥n pendiente:** Product Owner